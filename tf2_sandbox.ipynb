{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from __future__ import absolute_import, division, print_function, unicode_literals"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"# Import system helpers\nimport os\nimport pathlib\nfrom os import listdir\nfrom os.path import isfile, join\n\n# Import TensorFlow and tf.keras\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import datasets, layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Import helper libraries\nimport numpy as np\nimport pandas as pd\nimport scipy.io\nimport matplotlib.pyplot as plt\nimport IPython.display as display\nfrom PIL import Image\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"cars_meta = np.squeeze(scipy.io.loadmat(os.path.join(sc_devkit, 'cars_meta.mat'))['class_names'])"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"ucf_data='/Users/katerina/Workspace/visual_census/ucf_data'\ncolor_hist = np.squeeze(scipy.io.loadmat(os.path.join(ucf_data, 'Color_hist.mat'))['color_hist'])\ngist = np.squeeze(scipy.io.loadmat(os.path.join(ucf_data, 'GIST.mat'))['RefImGIST'])\ngps = np.squeeze(scipy.io.loadmat(os.path.join(ucf_data, 'GPS_Long_Lat_Compass.mat'))['GPS_Compass'])\nlocation = np.squeeze(scipy.io.loadmat(os.path.join(ucf_data, 'Cartesian_Location_Coordinates.mat'))['XYZ_Cartesian'])"},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":"array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=uint16)"},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["color_hist"]},{"cell_type":"code","execution_count":117,"metadata":{},"outputs":[],"source":"class_labels = (np.array([np.squeeze(x) for x in annotations['class']]) - 1).tolist()\nimage_fnames = np.array([np.squeeze(x) for x in annotations['fname']])\nbb_y1 = np.array([np.squeeze(x) for x in annotations['bbox_y1']])\nbb_x1 = np.array([np.squeeze(x) for x in annotations['bbox_x1']])\nbb_y2 = np.array([np.squeeze(x) for x in annotations['bbox_y2']])\nbb_x2 = np.array([np.squeeze(x) for x in annotations['bbox_x2']])"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["cars_meta = np.squeeze(scipy.io.loadmat(os.path.join(sc_devkit, 'cars_meta.mat'))['class_names'])\n","full_label_names = [x[0] for x in cars_meta]\n","mnfr_label_names = [x[0].split(' ')[0] for x in cars_meta]\n","year_label_names = [x[0].split(' ')[-1] for x in cars_meta]"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["full_labels = [full_label_names[id] for id in class_labels]"]},{"cell_type":"code","execution_count":122,"metadata":{},"outputs":[],"source":"def read_stanford_cars_data(sc_devkit='/Users/katerina/Workspace/visual_census/data/devkit'):\n    # Convert .mat to Python dict with Scipy.io\n    cars_meta = np.squeeze(scipy.io.loadmat(os.path.join(sc_devkit, 'cars_meta.mat'))['class_names'])\n    full_label_names = [x[0] for x in cars_meta]\n    mnfr_label_names = [x[0].split(' ')[0] for x in cars_meta]\n    year_label_names = [x[0].split(' ')[-1] for x in cars_meta]\n\n    annotations = np.squeeze(scipy.io.loadmat(os.path.join(sc_devkit, 'cars_train_annos.mat'))['annotations'])\n    class_labels = (np.array([np.squeeze(x) for x in annotations['class']]) - 1).tolist()\n    image_fnames = np.array([np.squeeze(x) for x in annotations['fname']])\n\n    bb_y1 = np.array([np.squeeze(x) for x in annotations['bbox_y1']])\n    bb_x1 = np.array([np.squeeze(x) for x in annotations['bbox_x1']])\n    bb_y2 = np.array([np.squeeze(x) for x in annotations['bbox_y2']])\n    bb_x2 = np.array([np.squeeze(x) for x in annotations['bbox_x2']])\n\n    full_labels = [full_label_names[idx] for idx in class_labels] \n    mnfr_labels = [mnfr_label_names[idx] for idx in class_labels] \n    year_labels = [year_label_names[idx] for idx in class_labels] \n\n    bboxes = [(y1, x1, y2, x2) for y1, x1, y2, x2 in zip(bb_y1, bb_x1, bb_y2, bb_x2)]\n\n    return full_labels, mnfr_labels, year_labels, image_fnames, bboxes"},{"cell_type":"code","execution_count":123,"metadata":{},"outputs":[],"source":"full_labels, mnfr_labels, year_labels, image_fnames, bboxes = read_stanford_cars_data(sc_devkit='/Users/katerina/Workspace/visual_census/data/devkit')"},{"cell_type":"code","execution_count":134,"metadata":{},"outputs":[{"data":{"text/plain":"'00002.jpg'"},"execution_count":134,"metadata":{},"output_type":"execute_result"}],"source":["image_fnames[1]"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":"def get_car_labels(sc_devkit='/Users/katerina/Workspace/visual_census/data/devkit'):\n        \n    # Convert .mat to Python dict with Scipy.io\n    cars_meta = scipy.io.loadmat(os.path.join(sc_devkit, 'cars_meta.mat'))['class_names']\n    cars_train_annos = scipy.io.loadmat(os.path.join(sc_devkit, 'cars_train_annos.mat'))['annotations']\n    cars_test_annos = scipy.io.loadmat(os.path.join(sc_devkit, 'cars_test_annos.mat'))['annotations']\n\n    # Extract Car Metadata from dictionary to an array\n    car_makes = []\n    for vehicle in cars_meta[0]:\n        car_makes.append([vehicle[0],vehicle[0].split(' ')[0], vehicle[0].split(' ')[-1]])\n    car_makes = pd.DataFrame(car_makes, columns=['full_label', 'mnfr', 'year'])\n\n    car_makes.index += 1\n    car_mnfr = dict(zip(car_makes.index, car_makes.mnfr))\n    car_year = dict(zip(car_makes.index, car_makes.year))\n    car_full_label = dict(zip(car_makes.index, car_makes.full_label))\n\n    cars_train_labels = {}\n    cars_train_annotations = {}\n    for anno in cars_train_annos[0]:\n        cars_train_labels[anno[5][0]] = anno[4][0][0]\n        cars_train_annotations[anno[5][0]] = [anno[0][0][0], anno[1][0][0], anno[2][0][0], anno[3][0][0]]\n\n    return car_mnfr, car_year, car_full_label, cars_train_labels, cars_train_annotations"},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":"car_mnfr, car_year, car_full_label, cars_train_labels, cars_train_annotations = get_car_labels(sc_devkit='/Users/katerina/Workspace/visual_census/data/devkit')"},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["for filename, label in cars_train_labels.items():\n","      mnfr_string = str.encode(car_mnfr[label])\n","      year_string = str.encode(car_year[label])\n","      full_string = str.encode(car_full_label[label])\n","\n","      bb_x1 = cars_train_annotations[filename][0]\n","      bb_x2 = cars_train_annotations[filename][1]\n","      bb_y1 = cars_train_annotations[filename][2]\n","      bb_y2 = cars_train_annotations[filename][3]"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":"dtype('uint8')"},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":"bb_x1.dtype"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"\nimages = []\nlabels = []\nfor features in ds.take(1000):\n    image = tf.image.decode_image(features['image_raw'], channels=3)\n    image = tf.image.resize(image, [224, 224])\n    images.append(image.numpy())\n    labels.append(features['label'].numpy())\n\ntrain_images, test_images = np.array(images[:800]), np.array(images[800:])\ntrain_labels, test_labels = np.array(labels[:800])-1, np.array(labels[800:])-1\n\n# Normalize pixel values to be between 0 and 1\ntrain_images, test_images = train_images / 255.0, test_images / 255.0"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"car_names = list(car_makes['mnfr'])"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"plt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_images[i], cmap=plt.cm.binary)\n    # The CIFAR labels happen to be arrays, \n    # which is why you need the extra index\n    plt.xlabel(car_names[train_labels[i]])\nplt.show()"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"model = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"model.summary()"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"model.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(196, activation='softmax'))"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"model.summary()"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(train_images, train_labels, epochs=10, \n                    validation_data=(test_images, test_labels))"},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":"[0, 0, 0, 1, 1, 2]"},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":"class_label_names = [\"cat\", \"kitti\", \"putty\"]\n\nreal_labels = ['cat', 'cat', 'cat', 'kitti', 'kitti', 'putty']\n\n[class_label_names.index(label) for label in real_labels]\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}